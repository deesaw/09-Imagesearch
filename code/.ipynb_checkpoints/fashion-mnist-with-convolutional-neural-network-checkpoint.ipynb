{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion MNIST with Convolutional Neural Network\n",
    "\n",
    "\n",
    "![](http://www.researchgate.net/profile/Lina_Yao4/publication/325921786/figure/fig2/AS:640163516522496@1529638284313/Example-for-fashion-MNIST-Each-class-is-represented-by-nine-cases.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an image from file\n",
    "image = load_img('dog.jpg', target_size=(224, 224))\n",
    "print(image.shape)\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)\n",
    "print(image.shape)\n",
    "# reshape data for the model\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "print(image.shape)\n",
    "# prepare the image for the VGG model\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as ft\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# load the fashion mnist dataset from Keras API\n",
    "\n",
    "(train_images_full, train_labels_full), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback when the model reaches 99% accuracy\n",
    "\n",
    "class tfCallback(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if logs.get(\"accuracy\")>=0.95:\n",
    "      print(\"\\nReached 95% accuracy!\")\n",
    "      self.model.stop_training = True \n",
    "\n",
    "callbacks=tfCallback()\n",
    "\n",
    "# preprocess the the dataset\n",
    "\n",
    "train_images_full = train_images_full.reshape(60000, 28, 28, 1)\n",
    "train_images_full = train_images_full / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation set with 5000 examples from the training set\n",
    "\n",
    "validation_images, train_images = train_images_full[:5000], train_images_full[5000:]\n",
    "validation_labels, train_labels = train_labels_full[:5000], train_labels_full[5000:]\n",
    "\n",
    "print(validation_images.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a deep learning model with 2 CNN layers and a densely connected layer\n",
    "\n",
    "model = keras.models.Sequential([layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
    "                                 layers.MaxPooling2D(2,2),\n",
    "                                 layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "                                 layers.MaxPooling2D(2,2),\n",
    "                                 layers.Dropout(0.2),\n",
    "                                 layers.Flatten(),\n",
    "                                 layers.Dense(128, activation=\"relu\"),\n",
    "                                 layers.Dense(10, activation=\"softmax\")])\n",
    "\n",
    "# use adam for model optimization\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_images, \n",
    "                    train_labels, \n",
    "                    epochs=50,\n",
    "                    validation_data=(validation_images, validation_labels),\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss\n",
    "\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, accuracy, \"b-\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"bo\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.plot(epochs, loss, \"r-\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"ro\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on test set\n",
    "\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_images)\n",
    "\n",
    "print(prediction[6])\n",
    "print(test_labels[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
